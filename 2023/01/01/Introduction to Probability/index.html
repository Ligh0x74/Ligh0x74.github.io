<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Introduction to Probability - Ligh0x74&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Ligh0x74&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Ligh0x74&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="参考 Introduction to Probability，MIT 6.041SC FALL 2013，Probability Cheatsheet。 Unit I: Probability Models And Discrete Random Variables Lecture 2: Conditioning and Bayes’ Rule 条件概率 \(P(A \mid B)\) 表示在 \"><meta property="og:type" content="blog"><meta property="og:title" content="Introduction to Probability"><meta property="og:url" content="https://ligh0x74.github.io/2023/01/01/Introduction%20to%20Probability/"><meta property="og:site_name" content="Ligh0x74&#039;s Blog"><meta property="og:description" content="参考 Introduction to Probability，MIT 6.041SC FALL 2013，Probability Cheatsheet。 Unit I: Probability Models And Discrete Random Variables Lecture 2: Conditioning and Bayes’ Rule 条件概率 \(P(A \mid B)\) 表示在 \"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://ligh0x74.github.io/img/Math.assets/1751531335840.png"><meta property="og:image" content="https://ligh0x74.github.io/img/Math.assets/1751685942801.png"><meta property="og:image" content="https://ligh0x74.github.io/img/Math.assets/1751878580486.png"><meta property="og:image" content="https://ligh0x74.github.io/img/Math.assets/1752026105461.png"><meta property="article:published_time" content="2022-12-31T16:00:00.000Z"><meta property="article:modified_time" content="2025-07-09T11:27:39.934Z"><meta property="article:author" content="Ligh0x74"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://ligh0x74.github.io/img/Math.assets/1751531335840.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://ligh0x74.github.io/2023/01/01/Introduction%20to%20Probability/"},"headline":"Introduction to Probability","image":["https://ligh0x74.github.io/img/Math.assets/1751531335840.png","https://ligh0x74.github.io/img/Math.assets/1751685942801.png","https://ligh0x74.github.io/img/Math.assets/1751878580486.png","https://ligh0x74.github.io/img/Math.assets/1752026105461.png"],"datePublished":"2022-12-31T16:00:00.000Z","dateModified":"2025-07-09T11:27:39.934Z","author":{"@type":"Person","name":"Ligh0x74"},"publisher":{"@type":"Organization","name":"Ligh0x74's Blog","logo":{"@type":"ImageObject","url":"https://ligh0x74.github.io/img/logo.svg"}},"description":"参考 Introduction to Probability，MIT 6.041SC FALL 2013，Probability Cheatsheet。 Unit I: Probability Models And Discrete Random Variables Lecture 2: Conditioning and Bayes’ Rule 条件概率 \\(P(A \\mid B)\\) 表示在 \\"}</script><link rel="canonical" href="https://ligh0x74.github.io/2023/01/01/Introduction%20to%20Probability/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/monokai.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Ligh0x74&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/links">Links</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-12-31T16:00:00.000Z" title="2023/1/1 00:00:00">2023-01-01</time>发表</span><span class="level-item"><time dateTime="2025-07-09T11:27:39.934Z" title="2025/7/9 19:27:39">2025-07-09</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E5%9F%BA%E7%A1%80/">基础</a><span> / </span><a class="link-muted" href="/categories/%E5%9F%BA%E7%A1%80/%E6%95%B0%E5%AD%A6/">数学</a></span><span class="level-item">24 分钟读完 (大约3533个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">Introduction to Probability</h1><div class="content"><p>参考 <a target="_blank" rel="noopener" href="http://www.athenasc.com/probbook.html">Introduction to Probability</a>，<a target="_blank" rel="noopener" href="https://ocw.mit.edu/courses/6-041sc-probabilistic-systems-analysis-and-applied-probability-fall-2013/">MIT 6.041SC FALL 2013</a>，<a target="_blank" rel="noopener" href="http://www.wzchen.com/probability-cheatsheet/">Probability Cheatsheet</a>。</p>
<h2 id="Unit-I-Probability-Models-And-Discrete-Random-Variables">Unit I: Probability Models And Discrete Random Variables</h2>
<h3 id="Lecture-2-Conditioning-and-Bayes’-Rule">Lecture 2: Conditioning and Bayes’ Rule</h3>
<p>条件概率 \(P(A \mid B)\) 表示在 \(B\) 发生的前提下 \(A\) 发生的概率，此时 \(B\) 作为全集，\(A\) 在 \(B\) 中的占比就是该条件概率的值。如果乘以 \(P(B)\) 就是将 \(\Omega\) 作为全集，自然会得到 \(P(A \cap B)\)。反之， 将 \(P(A \cap B)\) 除以 \(P(B)\) 就是将全集 \(\Omega\) 缩减为 \(B\)，从而得到条件概率 \(P(A \mid B)\)，此时要求 \(P(B) \neq 0\)。</p>
<div>
$$
P(A \cap B) = P(B)P(A \mid B) = P(A)P(B \mid A)
$$
</div>
<div>
$$
P(B) = P(A)P(B \mid A) + P(A^{c})P(B \mid A^{c})
$$
</div>
<div>
$$
P(A_{i} \mid B)
= \frac{P(A_{i} \cap B)}{P(B)}
= \frac{P(A_{i})P(B \mid A_{i})}{P(B)}
= \frac{P(A_{i})P(B \mid A_{i})}{\sum_{j}P(A_{j})P(B \mid A_{j})}
$$
</div>
<h3 id="Lecture-3-Independence">Lecture 3: Independence</h3>
<p>如果 \(A\) 和 \(B\) 独立，则 \(P(B \mid A) = P(B)\)，\(P(A \cap B) = P(A)P(B)\)。如果 \(A\) 和 \(B\) 互斥，则 \(P(A \cap B) = 0\)。如果 \(P(A), P(B) \gt 0\)，互斥必然不独立，独立必然不互斥。如果 \(A\) 和 \(B\) 独立，则其在 \(C\) 发生的前提下不一定独立，即独立不意味着条件独立。如果 \(A, B, C\) 两两独立，不意味着 \(A, B, C\) 独立。</p>
<p><img src="/img/Math.assets/1751531335840.png" alt=""></p>
<p>例如，假设抛两次硬币，\(A\) 表示第一次是正面，\(B\) 表示第二次是正面，这两个事件是独立的。如果 \(C\) 表示两次同面，则在 \(C\) 发生的前提下 \(A\) 和 \(B\) 不独立。此时 \(A, B, C\) 两两独立，但是 \(P(A \cap B \cap C) \neq P(A)P(B)P©\)，即 \(A, B, C\) 不独立。如果两次中有一次是正面，则另一次是反面的概率是多少？答案是 \(\frac{2}{3}\) 而不是 \(\frac{1}{2}\)，虽然 \(A\) 和 \(B\) 独立，但是原始样本空间的大小是 \(4\) 而不是 \(2\)，这个需要特别注意。</p>
<h3 id="Lecture-4-Counting">Lecture 4: Counting</h3>
<p>包含 \(n\) 个元素的集合，有 \(n!\) 个排列，\(2^{n}\) 个子集。从中选择 \(k\) 个元素，有 \(\binom{n}{k} = \frac{n!}{(n - k)!k!}\) 种情况，除以 \(k!\) 表示去除相同元素不同排列的情况。将 \(52\) 张牌平均分成 \(4\) 份，每份中都有 \(A\) 的概率是多少？答案是 \(\frac{13^{4}}{C_{52}^{4}}\)，表示从 \(52\) 个位置选择 \(4\) 个位置放 \(A\)，符合条件的情况是每 \(13\) 个位置选择 \(1\) 个位置放 \(A\)。另一个办法是，将 \(52\) 张牌均分，符合条件的情况是单独分 \(A\) 再将 \(48\) 张牌均分，得到 \(\frac{4!C_{48}^{12}C_{36}^{12}C_{24}^{12}C_{12}^{12}}{C_{52}^{13}C_{39}^{13}C_{26}^{13}C_{13}^{13}}\)，化简之后和上述答案相同。</p>
<div>
$$
(a + b)^{n} = \sum_{k = 0}^{n}\binom{n}{k}a^{k}b^{n - k}
$$
</div>
<h3 id="Lecture-5-Discrete-Random-Variables-Probability-Mass-Functions-Expectations">Lecture 5: Discrete Random Variables; Probability Mass Functions; Expectations</h3>
<p>随机变量是函数，将样本空间 \(\Omega\) 映射到实数。如下概率质量函数（PMF），表示随机变量 \(X\) 的值为 \(x\) 的概率。例如，假设抛一次硬币是正面的概率为 \(P(H) = p\)，则抛 \(n\) 次硬币有 \(k\) 次是正面的 PMF 为 \(p_{X}(k) = \binom{n}{k}p^{k}(1 - p)^{n - k}\)（二项分布的 PMF），随机变量 \(X\) 将抛 \(n\) 次硬币的样本空间映射到硬币是正面的次数，\(n\) 越大该函数图像越接近钟型曲线。如果连续抛硬币直到正面为止，则抛 \(k\) 次才停止的 PMF 为 \(p_{X}(k) = (1 - p)^{k - 1}p\)（几何分布的 PMF）。</p>
<div>
$$
p_{X}(x)
= P(X = x)
= P(\{\omega \in \Omega\ \text{s.t.}\ X(\omega) = x\}),\
p_{X}(x) \geq 0,\
\sum_{x}p_{X}(x) = 1
$$
</div>
<p>随机变量 \(X\) 的期望为 \(E[x] = \sum_{x}xp_{X}(x)\)，可以将概率 \(p_{X}(x)\) 视为 \(x\) 出现的频率，期望视为 \(x\) 根据概率的加权平均值，或者将期望看作 PMF 的重心。假设随机变量 \(Y\) 是关于随机变量 \(X\) 的函数 \(Y = g(X)\)，则有如下公式计算 \(Y\) 的期望（无意识统计学家法则，LOTUS）。通常情况下 \(E[g(X)] \neq g(E[X])\)，除非 \(g\) 是线性函数。方差（Variance）是随机变量和自身期望的偏差平方的期望，用于描述随机变量的离散程度。</p>
<div>
$$
E[y] = \sum_{y}yp_{Y}(y) = \sum_{x}g(x)p_{X}(x) \quad (Y = g(X))
$$
</div>
<div>
$$
E[\alpha] = \alpha,\
E[\alpha X] = \alpha E[X],\
E[\alpha X + \beta] = \alpha E[x] + \beta
\quad (\alpha, \beta \text{ are constants})
$$
</div>
<div>
$$
\DeclareMathOperator{\var}{var}
E[X^{2}] = \sum_{x}x^{2}p_{X}(x),\
E[X - E[x]] = E[x] - E[x] = 0 \\
\var(X) = E[(X - E[X])^{2}] = \sum_{x}(x - E[x])^{2}p_{X}(x) = E[X^{2}] - (E[X])^{2} \\
\var(X) \geq 0,\
\var(\alpha X + \beta) = \alpha^{2}\var(X),\
\sigma_{X} = \sqrt{\var(X)}
$$
</div>
<h3 id="Lecture-6-Discrete-Random-Variable-Examples-Joint-PMFs">Lecture 6: Discrete Random Variable Examples; Joint PMFs</h3>
<p>随机变量 \(X\) 的条件 PMF 为 \(p_{X \mid A}(x) = P(X = x \mid A)\)，条件期望为 \(E[X \mid A] = \sum_{x}xp_{X \mid A}(x)\)。几何分布的期望为 \(E[X] = \sum_{k = 1}^{\infty}k(1 - p)^{k - 1}p\)，几何分布具有无记忆性（Memoryless），\(p_{X - 2 \mid X \gt 2}(k) = p_{X}(k)\)，过去发生的事情不会影响未来发生的事情。结合几何分布的无记忆性和如下全期望定理可以推出几何分布的期望为 \(E[X] = \frac{1}{p}\)，使用错位相减化简或者对几何级数求导也可以得到该结果。</p>
<div>
$$
P(B) = P(A_{1})P(B \mid A_{1}) + \cdots + P(A_{n})P(B \mid A_{n})
$$
</div>
<div>
$$
p_{X}(x) = P(A_{1})p_{X \mid A_{1}}(x) + \cdots + P(A_{n})p_{X \mid A_{n}}(x) \rightarrow
E[X] = P(A_{1})E[X \mid A_{1}] + \cdots + P(A_{n})E[X \mid A_{n}]
$$
</div>
<div>
$$
E[X] = P(X = 1)E[X \mid X = 1] + P(X \gt 1)E[X \mid X \gt 1] \rightarrow
E[x] = p \cdot 1 + (1 - p) \cdot (E[X] + 1) \rightarrow
E[x] = \frac{1}{p}
$$
</div>
<p>随机变量 \(X\) 和 \(Y\) 的联合 PMF 为 \(p_{X, Y}(x, y) = P(X = x, Y = y)\)，满足以下性质。可以通过联合 PMF 得到单个随机变量的边缘 PMF，条件 PMF 表示在 \(Y = y\) 的前提下 \(X = x\) 的概率，除以 \(p_{Y}(y)\) 将全集缩减到 \(Y = y\) 的情况。条件 PMF 和普通 PMF 相同，概率求和得到 \(1\)。</p>
<div>
$$
\sum_{x}\sum_{y}p_{X, Y}(x, y) = 1,\
p_{X}(x) = \sum_{y}p_{X, Y}(x, y),\
p_{X \mid Y}(x \mid y) = P(X = x \mid Y = y) = \frac{p_{X, Y}(x, y)}{p_{Y}(y)},\
\sum_{x}p_{X \mid Y}(x \mid y) = 1
$$
</div>
<h3 id="Lecture-7-Multiple-Discrete-Random-Variables">Lecture 7: Multiple Discrete Random Variables</h3>
<p>如果随机变量 \(X, Y, Z\) 独立，则 \(p_{X, Y, Z} = p_{X}(x) \cdot p_{Y}(y) \cdot p_{Z}(x)\)，此时 \(p_{X \mid Y, Z}(x \mid y, z) = p_{X}(x)\)。</p>
<div>
$$
P(A \cap B \cap C) = P(A)P(B \mid A)P(C \mid A \cap B) \rightarrow
p_{X, Y, Z}(x, y, z) = p_{X}(x)p_{Y \mid X}(y \mid x)p_{Z \mid X, Y}(z \mid x, y)
$$
</div>
<div>
$$
E[g(X, Y)] = \sum_{x}\sum_{y}g(x, y)p_{X, Y}(x, y),\
E[X + Y + Z] = E[X] + E[Y] + E[Z]
$$
</div>
<div>
$$
\DeclareMathOperator{\var}{var}
E[XY] = E[X]E[Y],\
E[g(X)h(Y)] = E[g[X]]e[h(Y)],\
\var(X + Y) = \var(X) + \var(Y)
\quad (X, Y \text{ are independent})
$$
</div>
<p>二项分布的期望和方差如下，有 \(X = \sum_{i = 1}^{n}X_{i}\)，其中 \(X_{i}\) 表示第 \(i\) 次试验是否成功的指示变量。</p>
<div>
$$
\DeclareMathOperator{\var}{var}
E[X] = \sum_{k = 0}^{n}k\binom{n}{k}p^{k}(1 - p)^{n - k},\
E[X_{i}] = 1 \cdot p + 0 \cdot (1 - p) = p,\
E[X] = \sum_{i = 1}^{n}E[X_{i}] = np \\
\var(X_{i}) = p(1 - p)^{2} + (1 - p)(0 - p)^{2} = E[X_{i}^{2}] - E[X_{i}]^{2} = p(1 - p),\
\var(X) = \sum_{i = 1}^{n}\var(X_{i}) = np(1 - p)
$$
</div>
<h2 id="Unit-II-General-Random-Variables">Unit II: General Random Variables</h2>
<h3 id="Lecture-8-Continuous-Random-Variables">Lecture 8: Continuous Random Variables</h3>
<p>连续型随机变量由概率密度函数（PDF）\(f_{X}\) 描述，密度（函数值）不是概率，该函数和 \(x\) 轴围成的面积才是概率。和 PMF 不同，PDF 在某点的概率总是零，因为面积是零。连续型和离散型随机变量的累积分布函数（CDF）\(F(x)\) 如下所示，连续型随机变量的 CDF 的导数等于密度，即密度是 CDF 的变化率。</p>
<div>
$$
P(a \leq X \leq b) = \int_{a}^{b}f_{X}(x)dx,\
f_{X} \geq 0,\
\int_{-\infty}^{\infty}f_{X}(x)dx = 1,\
P(x \leq X \leq x + \delta) = \int_{x}^{x + \delta}f_{X}(s)ds \approx f_{X}(x) \cdot \delta
$$
</div>
<div>
$$
\DeclareMathOperator{\var}{var}
E[X] = \int_{-\infty}^{\infty}xf_{X}(x)dx,\
E[g(X)] = \int_{-\infty}^{\infty}g(x)f_{X}(x)dx,\
\var(X) = \sigma_{X}^{2} = \int_{-\infty}^{\infty}(x - E[X])^{2}f_{X}(x)dx
$$
</div>
<div>
$$
F_{X}(x) = P(X \leq x) = \int_{-\infty}^{x}f_{X}(t)dt,\
F_{X}(x) = P(X \leq x) = \sum_{k \leq x}p_{X}(k)
$$
</div>
<p><img src="/img/Math.assets/1751685942801.png" alt=""></p>
<p>正态分布（高斯分布）的 PDF 如下所示。标准正态分布的均值为 \(0\)，方差为 \(1\)。一般正态分布的均值为 \(\mu\)，方差为 \(\sigma^{2}\)，相当于将函数图像向右移动 \(\mu\)，然后 \(\sigma\) 越小图像越窄，因为 \(e\) 的指数降低得更快。系数 \(\frac{1}{\sqrt{2\pi}}\) 和 \(\frac{1}{\sigma\sqrt{2\pi}}\) 确保 PDF 在整个实数域上的积分是 \(1\)。如果 \(X \sim N(\mu, \sigma^{2})\)，则 \(\frac{X - \mu}{\sigma} \sim N(0, 1)\)。</p>
<div>
$$
\DeclareMathOperator{\var}{var}
f_{X}(x) = \frac{1}{\sqrt{2\pi}}e^{-x^{2} / 2},\
E[X] = 0,\
\var(X) = 1
\quad N(0, 1)
$$
</div>
<div>
$$
\DeclareMathOperator{\var}{var}
f_{X}(x) = \frac{1}{\sigma\sqrt{2\pi}}e^{-(x - \mu)^{2} / 2\sigma^{2}},\
E[X] = \mu,\
\var(X) = \sigma^{2}
\quad N(\mu, \sigma^{2})
$$
</div>
<div>
$$
\DeclareMathOperator{\var}{var}
X \sim N(\mu, \sigma^{2}),\
Y = aX + b \rightarrow
E[Y] = a\mu + b,\
\var(Y) = a^{2}\sigma^{2},\
Y \sim N(a\mu + b, a^{2}\sigma^{2})
$$
</div>
<h3 id="Lecture-9-Multiple-Continuous-Random-Variables">Lecture 9: Multiple Continuous Random Variables</h3>
<p>随机变量 \(X\) 和 \(Y\) 的联合 PDF、期望、边缘 PDF 和条件 PDF 如下，联合 PDF 表示的曲顶柱体的体积就是概率，在整个曲面下的体积 \(\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}f_{X, Y} = 1\)，密度 \(f_{X, Y} \geq 0\)。将前提 \(y\) 视为常量，条件 PDF 可以看作联合 PDF 的切片。</p>
<div>
$$
P((X, Y) \in S) = \int\int_{S}f_{X, Y}(x, y)dxdy,\
P(x \leq X \leq x + \delta, y \leq Y \leq y + \delta) \approx f_{X, Y}(x, y) \cdot \delta^{2}
$$
</div>
<div>
$$
E[g(X, Y)] = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}g(x, y)f_{X, Y}(x, y)dxdy
$$
</div>
<div>
$$
f_{X}(x) \cdot \delta \approx P(x \leq X \leq x + \delta)
= \int_{-\infty}^{\infty}\int_{x}^{x + \delta}f_{X, Y}(x, y)dxdy
\approx \int_{-\infty}^{\infty}\delta \cdot f_{X, Y}(x, y)dy \rightarrow
f_{X}(x) = \int_{-\infty}^{\infty}f_{X, Y}(x, y)dy
$$
</div>
<div>
$$
f_{X \mid Y}(x \mid y) = \frac{f_{X, Y}(x, y)}{f_{Y}(y)} \quad (f_{Y}(y) \gt 0)
$$
</div>
<div>
$$
f_{X, Y}(x, y) = f_{X}(x)f_{Y}(y),\
f_{X \mid Y}(x \mid y) = f_{X}(x) \quad (X, Y \text{ are independent})
$$
</div>
<p><img src="/img/Math.assets/1751878580486.png" alt=""></p>
<p>Buffon’s needle 问题：有两条距离为 \(d\) 的平行线，以及长度为 \(l\) 的针（\(l \lt d\)），求针和直线相交的概率。取随机变量 \(X\) 表示针的中点到两条平行线的最短距离，随机变量 \(\Theta\) 表示针和直线的夹角（锐角）。假设 \(X\) 和 \(\Theta\) 服从均匀分布且相互独立，则联合 PDF 公式如下。由于针和直线在 \(X \leq \frac{l}{2}\sin\Theta\) 时相交，所以相交的概率为 \(P(X \leq \frac{l}{2}\sin\Theta) = \frac{2l}{\pi d}\)。</p>
<div>
$$
f_{X, \Theta}(x, \theta)
= f_{X}(x)f_{\Theta}(\theta)
= \frac{2}{d}\frac{2}{\pi}
\quad (0 \leq x \leq d / 2, 0 \leq \theta \leq \pi / 2)
$$
</div>
<div>
$$
P(X \leq \frac{l}{2}\sin\Theta)
= \int\int_{x \leq \frac{l}{2}\sin\theta}f_{X}(x)f_{\Theta}(\theta)dxd\theta
= \frac{4}{\pi d}\int_{0}^{\pi / 2}\int_{0}^{(l /2)\sin\theta}dxd\theta
= \frac{2l}{\pi d}
$$
</div>
<h3 id="Lecture-10-Continuous-Bayes’-Rule-Derived-Distributions">Lecture 10: Continuous Bayes’ Rule; Derived Distributions</h3>
<div>
$$
p_{X \mid Y}(x \mid y)
= \frac{p_{X, Y}(x, y)}{p_{Y}(y)}
= \frac{p_{X}(x)p_{Y \mid X}(y \mid x)}{p_{Y}(y)},\
p_{Y}(y) = \sum_{x}p_{X}(x)p_{Y \mid X}(y \mid x)
$$
</div>
<div>
$$
f_{X \mid Y}(x \mid y)
= \frac{f_{X, Y}(x, y)}{f_{Y}(y)}
= \frac{f_{X}(x)f_{Y \mid X}(y \mid x)}{f_{Y}(y)},\
f_{Y}(y) = \int_{x}f_{X}(x)f_{Y \mid X}(y \mid x)dx
$$
</div>
<div>
$$
p_{X \mid Y}(x \mid y)
= \frac{p_{X}(x)f_{Y \mid X}(y \mid x)}{f_{Y}(y)},\
f_{Y}(y) = \sum_{x}p_{X}(x)f_{Y \mid X}(y \mid x)
$$
</div>
<div>
$$
f_{X \mid Y}(x \mid y)
= \frac{f_{X}(x)p_{Y \mid X}(y \mid x)}{f_{Y}(y)},\
p_{Y}(y) = \int_{x}f_{X}(x)p_{Y \mid X}(y \mid x)dx
$$
</div>
<p>对于离散型随机变量 \(X\)，已知 \(X\) 的 PMF，则 \(Y = g(X)\) 的 PMF 如下。对于连续型随机变量 \(X\)，已知 \(X\) 的 PDF，则 \(Y = g(X)\) 的 PDF 如下。可以使用以下公式证明，正态随机变量的线性函数仍服从正态分布。</p>
<div>
$$
p_{Y}(y) = P(g(X) = y) = \sum_{x: g(x) = y}p_{X}(x)
$$
</div>
<div>
$$
F_{Y}(y) = P(Y \leq y),\
f_{Y}(y) = \frac{dF_{Y}}{dy}(y) \rightarrow
Y = aX + b,\
f_{Y}(y) = \frac{1}{|a|}f_{X}(\frac{y - b}{a})
$$
</div>
<h3 id="Lecture-11-Derived-Distributions-Convolution-Covariance-and-Correlation">Lecture 11: Derived Distributions; Convolution; Covariance and Correlation</h3>
<p>如果 \(Y = g(X)\) 且函数 \(g\) 严格单调递增，则随机变量 \(X\) 和 \(Y\) 的 PMF 满足以下关系。如果 \(W = X + Y\) 且 \(X\) 和 \(Y\) 独立，则有如下卷积公式 \(p_{W}(w)\) 和 \(f_{W}(w)\)，分别对应离散和连续情况。可以使用卷积公式证明，独立的正态随机变量之和仍服从正态分布。</p>
<div>
$$
P(\ x \leq X \leq x + \delta) = P(g(x) \leq Y \leq g(x + \delta) \approx g(x) + \delta|\frac{dg}{dx}(x)|) \rightarrow
\delta f_{X}(x) = \delta \left|\frac{dg}{dx}(x)\right|f_{Y}(y)
$$
</div>
<div>
$$
p_{W}(w) = \sum_{x}P_{X}(x)p_{Y}(w - x),\
f_{W}(w) = \int_{-\infty}^{\infty}f_{X}(x)f_{Y}(w - x)
$$
</div>
<p><img src="/img/Math.assets/1752026105461.png" alt=""></p>
<p>协方差大于零说明 \(X\) 和 \(Y\) 成正相关，小于零说明成负相关。如果 \(X\) 和 \(Y\) 独立，则协方差为零，反之不一定成立。类似方差和标准差，为消除单位的影响，提出相关系数 \(\rho\) 的概念，表示变量之间的关联程度。</p>
<div>
$$
\DeclareMathOperator{\cov}{cov}
\cov(X, Y) = E\left[(X - E[X]) \cdot (Y - E[Y])\right]
$$
</div>
<div>
$$
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\cov}{cov}
\cov(X, X) = \var(X),\
\cov(X, Y) = E[XY] - E[X]E[Y],\
\var\left(\sum_{i = 1}^{n}X_{i}\right) = \sum_{i = 1}^{n}\var(X_{i}) + \sum_{(i, j): i \neq j}\cov(X_{i}, X_{j})
$$
</div>
<div>
$$
\DeclareMathOperator{\cov}{cov}
\rho = \frac{\cov(X, Y)}{\sigma_{X}\sigma_{Y}},\
-1 \leq \rho \leq 1
$$
</div>
<div>
$$
|\rho| = 1 \iff (X - E[X]) = c(Y - E[Y])
$$
</div>
<h3 id="Lecture-12-Iterated-Expectations-Sum-of-a-Random-Number-of-Random-Variables">Lecture 12: Iterated Expectations; Sum of a Random Number of Random Variables</h3>
<div>
$$
\DeclareMathOperator{\var}{var}
E[E[X \mid Y]] = \sum_{y}E[X \mid Y = y]p_{Y}(y) = E[X],\
\var(X) = E[\var(X \mid Y)] + \var(E[X \mid Y])
$$
</div>
<div>
$$
\DeclareMathOperator{\var}{var}
Y = \sum_{i = 1}^{N}X_{i},\
E[Y] = E[E[Y \mid N]] = E[NE[X]] = E[N]E[X],\
\var(Y) = E[\var(Y \mid N)] + \var(E[Y \mid N]) = E[N]\var(X) + (E[X])^{2}\var(N)
$$
</div>
<h2 id="Unit-IV-Laws-Of-Large-Numbers-And-Inference">Unit IV: Laws Of Large Numbers And Inference</h2>
</div><div class="article-licensing box"><div class="licensing-title"><p>Introduction to Probability</p><p><a href="https://ligh0x74.github.io/2023/01/01/Introduction to Probability/">https://ligh0x74.github.io/2023/01/01/Introduction to Probability/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Ligh0x74</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2023-01-01</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2025-07-09</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a><a class="icons" rel="noopener" target="_blank" title="ShareAlike" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><i class="icon fab fa-creative-commons-sa"></i></a></p></div></div></div></div></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2023/01/01/Calculus/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Calculus</span></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="content" id="waline-thread"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@waline/client@2.6.3/dist/waline.css"><script src="https://cdn.jsdelivr.net/npm/@waline/client@2.6.3/dist/waline.js"></script><script>Waline.init({
            el: '#waline-thread',
            serverURL: "https://blog-waline-ligh0x74.vercel.app",
            path: window.location.pathname,
            lang: "zh-CN",
            locale: {"placeholder":"Comment here..."},
            emoji: ["//unpkg.com/@waline/emojis@1.0.1/weibo"],
            dark: "auto",
            meta: ["nick","mail","link"],
            requiredMeta: [],
            login: "enable",
            
            pageSize: 10,
            imageUploader: false,
            
            texRenderer: false,
            search: false,
            pageview: false,
            comment: false,
            copyright: true,
        });</script></div></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Unit-I-Probability-Models-And-Discrete-Random-Variables"><span class="level-left"><span class="level-item">1</span><span class="level-item">Unit I: Probability Models And Discrete Random Variables</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Lecture-2-Conditioning-and-Bayes’-Rule"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">Lecture 2: Conditioning and Bayes’ Rule</span></span></a></li><li><a class="level is-mobile" href="#Lecture-3-Independence"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">Lecture 3: Independence</span></span></a></li><li><a class="level is-mobile" href="#Lecture-4-Counting"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">Lecture 4: Counting</span></span></a></li><li><a class="level is-mobile" href="#Lecture-5-Discrete-Random-Variables-Probability-Mass-Functions-Expectations"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">Lecture 5: Discrete Random Variables; Probability Mass Functions; Expectations</span></span></a></li><li><a class="level is-mobile" href="#Lecture-6-Discrete-Random-Variable-Examples-Joint-PMFs"><span class="level-left"><span class="level-item">1.5</span><span class="level-item">Lecture 6: Discrete Random Variable Examples; Joint PMFs</span></span></a></li><li><a class="level is-mobile" href="#Lecture-7-Multiple-Discrete-Random-Variables"><span class="level-left"><span class="level-item">1.6</span><span class="level-item">Lecture 7: Multiple Discrete Random Variables</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Unit-II-General-Random-Variables"><span class="level-left"><span class="level-item">2</span><span class="level-item">Unit II: General Random Variables</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Lecture-8-Continuous-Random-Variables"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">Lecture 8: Continuous Random Variables</span></span></a></li><li><a class="level is-mobile" href="#Lecture-9-Multiple-Continuous-Random-Variables"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">Lecture 9: Multiple Continuous Random Variables</span></span></a></li><li><a class="level is-mobile" href="#Lecture-10-Continuous-Bayes’-Rule-Derived-Distributions"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">Lecture 10: Continuous Bayes’ Rule; Derived Distributions</span></span></a></li><li><a class="level is-mobile" href="#Lecture-11-Derived-Distributions-Convolution-Covariance-and-Correlation"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">Lecture 11: Derived Distributions; Convolution; Covariance and Correlation</span></span></a></li><li><a class="level is-mobile" href="#Lecture-12-Iterated-Expectations-Sum-of-a-Random-Number-of-Random-Variables"><span class="level-left"><span class="level-item">2.5</span><span class="level-item">Lecture 12: Iterated Expectations; Sum of a Random Number of Random Variables</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Unit-IV-Laws-Of-Large-Numbers-And-Inference"><span class="level-left"><span class="level-item">3</span><span class="level-item">Unit IV: Laws Of Large Numbers And Inference</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Ligh0x74&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2025 Ligh0x74</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>